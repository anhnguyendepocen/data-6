{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Tables and Functions\n",
    "The tools that we've learned over the last week (for example, function definitions, histograms, and the table methods `where`, `apply`, and `group`) are enough to analyze a wide range of questions and datasets.  \n",
    "\n",
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "import datascience \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datascience import Table\n",
    "from datascience import *\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "Table.interactive_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading:\n",
    "- Textbook chapters [6](https://data-8r.gitbooks.io/textbook/chapters/06/tables.html) and [7](https://data-8r.gitbooks.io/textbook/chapters/07/functions-and-tables.html)\n",
    "\n",
    "Deadline:\n",
    "\n",
    "This assignment is due **Wednesday, August 5 at 11:59 PM**. You will receive an early submission bonus point if you turn in your final submission by **Tuesday, August 4 at 11:59 PM**. Late work will not be accepted unless you have made special arrangements with your (u)GSI or the instructor.\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. \n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. Drop-in office hours will be held at various times in the week; check bCourses for the latest schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cal Enviroscreen: Race & the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will use the CalEnviroScreen dataset that you may have seen in Chapter 3 of the textbook. From their [website](https://oehha.ca.gov/calenviroscreen/about-calenviroscreen): \"CalEnviroScreen is a mapping tool that helps identify California communities that are most affected by many sources of pollution, and where people are often especially vulnerable to pollution's effects.\"\n",
    "\n",
    "In general, there are disparities in environmental harms for different communities. Communities of color tend to receive a disproportionate share of the negative consequences of environmental actions and policies. Issues, such as increased pollution or dumping, often lead to worse health outcomes for those who are exposed. This is the basis of the environmental justice movement, which is defined as \"the fair treatment and meaningful involvement of all people, regardless of race, color, national origin, or income, with respect to the development, implementation, and enforcement of environmental laws, regulations and policies.\"\n",
    "\n",
    "The following table, `ces_data`, documents the percentage of various ethnicities, health outcomes, and exposure to negative environmental effects in census tracts (geographic tracts, similar to neighborhoods, for taking the census) in California. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run this cell.\n",
    "ces_data = Table.read_table('cal_enviroscreen.csv')\n",
    "ces_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by creating some tables to then compare histograms. A census tract's CES score (designated by the column `ces_pollution_score`) represent that tract's degree of burdens, such as various socioeconomic factors, sensitive population, and exposure to pollution. A higher score generally means that that community is more burdened. \n",
    "\n",
    "**Question 1.** We will spend most of our analysis looking at some of the most overburdened communities - those that rank in the **top 5%** of CES scores, called `ces_pollution_score`, in the state. Set `ces_percentile` to the score that is the 95th percentile in the dataset. \n",
    "\n",
    "**Note:** A percentile refers to a value that is *greater than or equal to* X% of the rest of the data after sorting the data from lowest to highest. For example, the 50th percentile is also the median in that it is greater than 50% of the values in the dataset and lower than 50%. We can calculate this by using the `percentile(X, array)` function, which takes 2 arguments: an integer (X) for the percentile you are searching and an array of the data to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ces_percentile = ...\n",
    "ces_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q1_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Given your percentile in Question 1, create a new table called `overburdened` that contains rows for all of the census tracts that have a CES pollution score **higher** than `ces_percentile`. We will use this table in our analysis to compare the ethnic makeup of each of the groups present in these communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overburdened = ...\n",
    "overburdened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q1_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This cell will graph histograms for each of the ethnic groups in the overburdened table. \n",
    "# Just run this cell, but click on the dropdown menu to view the various communities.\n",
    "\n",
    "def communities_hist(ethnicity):\n",
    "    overburdened.hist(ethnicity, bins = np.arange(0, 100, 5))\n",
    "\n",
    "interact(communities_hist, ethnicity=[\"african_american\", \"hispanic\", \"native_american\", \"asian_american\", \"white\", \"other\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** We will use the histogram above to calculate the following values. Notice that the bins are determined by the function np.arange(0, 100, 5), and that 377 census tracts are represented in `overburdened`. \n",
    "\n",
    "For each quantity listed below, either calculate its value using the histograms, or write *Unknown* if it is not possible to calculate the value numerically given the information we have. You are allowed to estimate each bar's height up to a tenth of a decimal place, and please **show your work** in the Markdown cell below.\n",
    "\n",
    "1. The **percentage** of census tracts that have Hispanic populations that make up 50-60% of the community.\n",
    "2. The **percentage** of census tracts that have African American populations that make up 3-5% of the community.\n",
    "4. The **number** of census tracts that have white communities that make up at least 40% of the community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*\n",
    "1. ...\n",
    "2. ...\n",
    "3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** If the histogram for Hispanic populations was redrawn with bins of width 10, what would be the height of the bar for the bin from 60-70%?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** The [Port of Oakland](https://en.wikipedia.org/wiki/Port_of_Oakland) is located in West Oakland and is one of the busiest ports in the United States. One of the census tracts located nearby is designated with the Census Tract ID (`census_tract`) 6001402200. Using the `ces_data` table and `where`, find the entry for the Port of Oakland.\n",
    "\n",
    "Then, find the ozone values and toxic release values as **floats** for the Port of Oakland and assign them to `port_ozone` and `port_tox_release`. Do not round the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "port_of_oakland = ...\n",
    "port_ozone = ...\n",
    "port_tox_release = ... \n",
    "port_of_oakland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q1_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** The Port, as a major shipping center, contributes to gas emissions (via diesel and greenhouse gas use in maritime operations) that may negatively affect air quality in the nearby areas. We will compare the asthma rates for the Port of Oakland and similar communities to the rest of the state in terms of **ozone and toxic release**, and we will find the similar tracts by using the [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance). Distance in this case is not necessarily geographic distance, but a measure of **how different or similar** two tracts are.\n",
    "\n",
    "You may have used this in the past as the Pythagorean theorem to measure the hypotenuse of a triangle. We will use it to find similar census tracts for our 2 traits - in this case, a smaller \"distance\" means that the two tracts are more similar.\n",
    "\n",
    "The equation is as follows (similar to a^2 + b^2 = c^2):\n",
    "\n",
    "((Tract Ozone - Port Ozone) `**` 2 + (Tract tox_release - Port tox_release) `**` 2) `**` (1/2)\n",
    "\n",
    "\n",
    "First, use `port_ozone`, `port_tox_release`, and `ces_data` to find the distances for ozone and toxic release rates between the Port of Oakland and the rest of the census tracts in California (`ces_data`) and save it to the variable `distances`. Then, create a table called `ces_with_distances` that is a copy of `ces_data`, but with an extra column called `distance_from_oak` containing the `distances` for each tract. \n",
    "\n",
    "**Note:** In a better analysis, we would need to standardize the units so we can better compare these 2 traits. Ozone is in parts per million (ppm) and Toxic Releases from facilities is a weighted measurement of various concentrations of chemicals released into the air. There is a way to do this that you will learn in Data 8 or another statistics class, if you decide to take one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distances = ...\n",
    "ces_with_distances = ...\n",
    "ces_with_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q1_6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Now that we have `ces_with_distances`, sort the table by `distance_from_oak` to find the tracts that are most similar to the Port of Oakland in terms of ozone and toxic release. Take the first 757 rows (10% of the table) and assign it to the variable `port_tracts`.\n",
    "\n",
    "*Hint:* Sort it so that the most similar (i.e. smallest distances) tracts are first in the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "port_tracts = ...\n",
    "port_tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q1_7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** Finally, create 2 histograms showing the distribution of `asthma` rates (measured in age-adjusted visits to emergency departments for asthma); one histogram will graph `ces_data` and the other will graph `port_tracts`. Use appropriate bins and make sure that both histograms have the **same** bins to compare. \n",
    "\n",
    "Do areas similar to the Port of Oakland in terms of ozone and toxic release emissions have higher rates of emergency department visits for asthma? Describe what you see in the Markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Type your code for both histograms here so they appear next to each other. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9.** In the following cell, we created a table called `random_ces_sample` which randomly selected 1000 census tracts without replacement. Using `random_ces_table`, create a scatter plot that compares the percent of people in `poverty` and the `ces_pollution_score` for that tract.\n",
    "\n",
    "Describe what you see and any associations or relationships between the two variables. If you do notice a pattern or relationship, what is a possible cause? Write your findings in the Markdown cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_ces_sample = ces_data.sample(1000, with_replacement = False)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with Text in Python: Fixing Misspellings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation is not limited to quantitative or numerical data. Oftentimes, social scientists– such as those in linguistics, sociology, legal studies, and communications– need to use Python or other languages to analyze text. This may be in the form of surveys, social media posts, court proceedings, or in this case, essays. In this section, we will do some basic text processing by using strings and functions to make some modifications to text. If you're interested in learning more about advanced text analysis that is used in many fields today, check out [Natural Language Processing (also known as NLP)](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32).\n",
    "\n",
    "For this example, imagine that you are editing a collection of your essays for publication, and you discover that you've been misspelling the word \"misspell\" as \"mispel\" your whole life.  You decide to use Python to correct this embarrassing mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Write a function called `correct_mispel`.  It should take a single string as its argument, and return the same string, but with all instances of \"mispel\" replaced with \"misspell\".\n",
    "\n",
    "*Hint:* Use the string method `.replace(\"to_replace\", \"replace_with\")`.  It takes two arguments: the piece of text you want to find, and the piece of text you want to replace it with.\n",
    "\n",
    "*Note:* When you create a function, it is good practice to make clear three things: what the function does, the purpose and type of each argument, and what the function returns. You can do this in the documentation or within the body of the function, and it allows others to use and understand your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# Write a function called correct_mispel in this cell.\n",
    "def ...(...):\n",
    "    \"\"\"...\"\"\"\n",
    "    ...\n",
    "    return ...\n",
    "\n",
    "correct_mispel(\"This sentence is mispeled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q2_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Now you need to load your data into Python.  The file `essay_filenames.csv` is a table that contains the *filenames* of your essays.  Each filename is a string that's the name of an essay.  Load it into a table called `essay_filenames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_filenames = ...\n",
    "essay_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q2_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Below, we've provided a function that takes as its argument the *filename* of an essay and returns the text in that file (as one long string).  Using `apply`, create a table called `essays` with two columns:\n",
    "\n",
    "1. \"Name\": The filename of the essay\n",
    "2. \"Text\": The whole text of the essay\n",
    "\n",
    "(The essays are actually books from [Project Gutenberg](gutenberg.org), modified to misspell \"misspel\".  Attributions and copyright information are contained in the text of each essay.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Just run this cell. Do not change anything in it.\n",
    "def load_essay(filename):\n",
    "    \"\"\"Loads the text in the given file, returning it as one long string.\"\"\"\n",
    "    with open(filename, 'r') as essay_file:\n",
    "        return essay_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essays = ...\n",
    "essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Using `tbl.apply()` and the `correct_mispel` function you wrote earlier, create a table called `corrected_essays` with two columns:\n",
    "\n",
    "1. \"Name\": The filename of the essay\n",
    "2. \"Corrected text\": The whole text of the essay, with \"mispel\" corrected as \"misspell\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrected_essays = ...\n",
    "corrected_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q2_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this do anything?  Were there even misspellings in the original essay?  Let's find out.\n",
    "\n",
    "**Question 5.** The string method `str.splitlines` produces an array of the lines of the string.  Use it to make a table called `news_writing_lines` with a single column called \"Line\" which contains the **original** lines from the text called \"news_writing.txt\". There should be one row in `news_writing_lines` for each line in the text called \"News Writing\"; there may be some empty rows, but you can ignore those.\n",
    "\n",
    "*Hint:* You don't need to use it, but `news_writing` is available to help break down the steps. How do you access the text of \"News Writing\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_writing = ...\n",
    "news_writing_lines = ...\n",
    "news_writing_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q2_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Use the table method `where` and the predicate `are.containing` to find all the lines in `news_writing_lines` that include the word \"mispel\".  Make a table of those lines called `misspelled_lines`.\n",
    "\n",
    "*Note:* You should also find versions of \"mispel\" like \"mispeled\" or \"mispeling\", and your code probably corrected those, too.  That's okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misspelled_lines = ...\n",
    "misspelled_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "grader.check('q2_6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** In the cell below, repeat the work you did in questions 5 and 6, but for the corrected version of \"News Writing\" you produced in `corrected_essays`. \n",
    "\n",
    "Did your correction fix the misspellings? If so, set fixed_typos to True. If not, you may need to check your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# Use this cell to check whether your code fixed the misspellings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed_typos = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q2_7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A \"data-driven pandemic\": COVID-19 in the United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is designed to give you practice using `group` and other table methods.\n",
    "\n",
    "We'll be looking at the COVID-19 Data Repository from Johns Hopkins University. You can find the raw data [here](https://github.com/CSSEGISandData/COVID-19). We've cleaned up the datasets a bit, but we will be investigating the number of confirmed cases and the number of new cases in the United States from March to June.\n",
    "\n",
    "The following table, `confirmed_cases`, contains the number of confirmed cases at the start of each month for every county in the United States, starting in March and ending in June."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Just run this cell. \n",
    "confirmed_cases = Table().read_table(\"covid_by_county.csv\")\n",
    "confirmed_cases.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** First, let's learn about how the number of confirmed cases has affected each state. Let's find the five states with the most COVID cases in June. \n",
    "\n",
    "To do that, create a table with two columns, one for the state and the other for the number of confirmed cases in June. There should be one row for each state and territory, and the total number of confirmed cases for that state in the month of June. Sort it in descending order by count, take the top 5 states, and assign the array of state strings to the variable `june_states`.\n",
    "\n",
    "*Note:* You should only need to use table methods to answer this question. Do not manually assign `june_states` to the strings of the state names. If you are struggling with this question, try breaking it down into its separate steps and use multiple variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "grouped_by_state = ...\n",
    "june_states = ...\n",
    "june_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check('q5_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Now, let's create a bar chart to compare some states. However, one problem is that these states have different populations, which makes it difficult to compare. Therefore, we will use **confirmed cases per capita** (total number of cases divided by total population) to compare across states.\n",
    "\n",
    "To help you, we've assigned `pop_by_state` to a 2 column table that contains the name and the total population of the state, and we assigned `west_coast` to a string that contains the names of the 5 West Coast states. \n",
    "\n",
    "Using these variables, create a single horizontal barplot that compares the 5 West Coast states using the confirmed cases per capita with separate bars for March, April, May, and June. (e.g. the Y-axis should be the states, the X-axis should be the confirmed cases per capita, and a separate set of bars for each month)\n",
    "\n",
    "*Hint:* This is a long question! You should use `grouped_by_state` if you defined it in the previous question, and array arithmetic to find the confirmed cases per capita for each month. It may also be easier to create a new table with a different column for each separate month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# Use this cell to make your plot.\n",
    "west_coast = make_array(\"Washington\", \"California\", \"Oregon\", \"Hawaii\", \"Alaska\")\n",
    "pop_by_state = Table().read_table(\"pop_by_state.csv\")\n",
    "\n",
    "west_coast_cases = ...\n",
    "confirmed_per_capita = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Finally, let's look at the number of new cases per day. We can calculate this by subtracting the number of confirmed cases in 1 day from the number of confirmed cases from the day after.\n",
    "\n",
    "For example: If Day 1 had 10, Day 2 had 25, and Day 3 had 15 cases, then we had an increase of 15 cases (25-15) and a decrease of 10 cases (25-15). \n",
    "\n",
    "This new table, `covid_by_state`, contains the number of confirmed cases in each state and territory in the United States, starting on March 1st and ending on June 9th (a total of 100 days). Complete the function `new_state_cases`, which will return a table with 2 columns that has the number of days since 3/1 and the number of new cases each day in that state.\n",
    "\n",
    "*Hint:* What function in numpy have we used in the past that lets us calcualte the difference between subsequent numbers in an array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Just run this cell.\n",
    "covid_by_state = Table().read_table(\"covid_by_state.csv\")\n",
    "covid_by_state.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Complete the following function. \n",
    "def new_state_cases(state):\n",
    "    \"\"\"Describe the function here.\"\"\"\n",
    "    new_cases = ...\n",
    "    num_days = ...\n",
    "    state_table = Table().with_columns(\"Days since 3/1/20\", ..., \n",
    "                                       \"New cases in \" + state, ...)\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run this cell. If you do not see a graph or receive an error, there is a problem with your function. \n",
    "new_state_cases(\"New York\").scatter(0)\n",
    "new_state_cases(\"California\").scatter(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## For your interest and exploration, the following function will let you choose 2 states and compare their trends.\n",
    "# Just run this cell. \n",
    "from ipywidgets import interact\n",
    "\n",
    "def two_state_cases(state1 = \"California\", state2 = \"New York\"):\n",
    "    \"\"\"Take in 2 states, find their new cases, and graph them together\"\"\"\n",
    "    state1tbl = new_state_cases(state1)\n",
    "    state2tbl = new_state_cases(state2)\n",
    "    two_state_cases_tbl = state1tbl.join(\"Days since 3/1/20\", state2tbl).relabel(1, state1).relabel(2, state2)\n",
    "    two_state_cases_tbl.scatter(0)\n",
    "\n",
    "interact(two_state_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Although there are significant amounts of data and reporting surrounding the COVID-19 pandemic, there are many factors that may confound our analysis. One example is the levels of testing; as our levels of testing increase, it is natural to assume that the number of new cases will rise as well. \n",
    "\n",
    "What are some factors with our data that may affect our findings? This may include how the data is collected or recorded, how it is analyzed, etc. Discuss them in a few sentences below.\n",
    "\n",
    "*Note:* If you are interested in why there may be problems with COVID-19 data, check out this [article](https://www.citylab.com/life/2020/05/coronavirus-data-positive-tests-deaths-covid-19-stats/610306/) by CityLab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submission\n",
    "\n",
    "To submit your homework, please download your notebook as a .ipynb file and submit to Gradescope. You can do so by navigating to the toolbar at the top of this page, clicking File > Download as... > Notebook (.ipynb). Then, go to our class's Gradescope page [here](https://www.gradescope.com/courses/136698) and upload your file under \"Homework 4\". \n",
    "\n",
    "To check your work, you may run the cell below. Remember that for homework assignments, passing the tests does not necessarily mean your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
